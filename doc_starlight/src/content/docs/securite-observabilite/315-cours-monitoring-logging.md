---
title: "Monitoring et Logging Docker"
description: "Guide Monitoring et Logging Docker"
sidebar:
  order: 315
---


## MONITORING

### Des mÃ©triques trÃ¨s dynamiques Ã  surveiller

```
Conteneur:
â”œâ”€ CPU Usage (%)
â”œâ”€ Memory Usage (MB/GB)
â”œâ”€ Memory Limit
â”œâ”€ Network I/O (MB/s)
â”œâ”€ Disk I/O (MB/s)
â””â”€ Nombre de processus

Cluster Swarm:
â”œâ”€ Nombre de nÅ“uds actifs
â”œâ”€ Services en Ã©tat "Running"
â”œâ”€ RÃ©plicas dÃ©marrÃ©s vs dÃ©sirÃ©s
â””â”€ Ressources disponibles par nÅ“ud
```

### Solutions de Monitoring

#### 2.1 Docker Stats (Natif - Basique)

```bash
# Voir les stats en temps rÃ©el
docker stats

# Format personnalisÃ©
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"

# Stats d'un service Swarm
docker service ps myapp --format "table {{.Name}}\t{{.Node}}\t{{.CurrentState}}"
```

#### cAdvisor (Google - Simple)

**CaractÃ©ristiques :**
- Interface web basique
- MÃ©triques en temps rÃ©el
- Historique limitÃ© (quelques minutes)
- Export vers Prometheus
- Se dÃ©ploie en mode global (1 instance par nÅ“ud)

**Interface :** http://localhost:8080

#### Prometheus + Grafana (Standard Industrie) â­

**Architecture :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Containers  â”‚â”€â”€â”€â”€â–¶â”‚ Prometheus  â”‚â”€â”€â”€â”€â–¶â”‚ Grafana  â”‚
â”‚  + cAdvisor  â”‚     â”‚  (MÃ©triques)â”‚     â”‚   (UI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Alertmanager â”‚
                     â”‚   (Alertes)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants :**
- **Prometheus** : Collecte et stockage des mÃ©triques (TSDB)
- **Grafana** : Visualisation et dashboards
- **Alertmanager** : Gestion et routage des alertes
- **cAdvisor** : Export des mÃ©triques conteneurs


#### Exemples de rÃ¨gles d'Alerte

**alert-rules.yml :**

```yaml
groups:
  - name: container_alerts
    interval: 30s
    rules:
      # Alerte CPU Ã©levÃ©
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPU Ã©levÃ© sur {{ $labels.name }}"
          description: "{{ $labels.name }} utilise {{ $value }}% CPU"

      # Alerte MÃ©moire Ã©levÃ©e
      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "MÃ©moire critique sur {{ $labels.name }}"
          description: "{{ $labels.name }} utilise {{ $value }}% de sa limite"

      # Alerte conteneur down
      - alert: ContainerDown
        expr: up == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Conteneur {{ $labels.job }} est down"
          description: "Le conteneur ne rÃ©pond plus depuis 2 minutes"

      # Alerte rÃ©plicas insuffisants
      - alert: ServiceReplicasMismatch
        expr: docker_swarm_service_replicas_running < docker_swarm_service_replicas_desired
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Service {{ $labels.service }} manque de rÃ©plicas"
```



### Dashboards Grafana RecommandÃ©s

```
Dashboard ID Ã  importer:
â”œâ”€ 193   : Docker and System Monitoring
â”œâ”€ 11600 : Docker Swarm & Container Overview
â”œâ”€ 893   : Docker & System Monitoring (cAdvisor)
â””â”€ 15798 : Docker Swarm Monitoring (complet)
```

**Importer un dashboard :**
1. Grafana â†’ Dashboards â†’ Import
2. Entrer l'ID (ex: 11600)
3. SÃ©lectionner la source Prometheus

### Comparaison Solutions Monitoring

| Solution | ComplexitÃ© | Historique | Alertes | UI | Clustering |
|----------|-----------|------------|---------|-----|------------|
| **docker stats** | â­ | âŒ | âŒ | CLI | âœ… |
| **cAdvisor** | â­â­ | Minutes | âŒ | Basique | âœ… |
| **Prometheus+Grafana** | â­â­â­â­ | âœ… 30j+ | âœ… | Excellente | âœ… |
| **Datadog** (SaaS) | â­â­ | âœ… IllimitÃ© | âœ… | Excellente | âœ… |
| **New Relic** (SaaS) | â­â­ | âœ… IllimitÃ© | âœ… | Excellente | âœ… |

**Recommandation :** Prometheus + Grafana pour production (gratuit, puissant, standard industrie)




## LOGGING

### Concepts Fondamentaux

#### Types de Logs

```
Application:
â”œâ”€ stdout/stderr (console)
â”œâ”€ Fichiers dans le conteneur
â””â”€ Logs applicatifs structurÃ©s (JSON)

Docker:
â”œâ”€ Container logs (docker logs)
â”œâ”€ Docker daemon logs
â””â”€ Swarm orchestration logs

SystÃ¨me:
â”œâ”€ Kernel logs (dmesg)
â”œâ”€ System logs (syslog)
â””â”€ Audit logs
```

#### Le ProblÃ¨me avec les Conteneurs

```
ProblÃ¨mes:
â”œâ”€ Logs Ã©parpillÃ©s sur plusieurs nÅ“uds
â”œâ”€ Conteneurs Ã©phÃ©mÃ¨res = perte de logs
â”œâ”€ Volumes de logs Ã©normes
â””â”€ Difficile de corrÃ©ler les Ã©vÃ©nements

Solution: Centralisation des logs
â”œâ”€ Collecter depuis tous les conteneurs
â”œâ”€ Stocker dans un systÃ¨me centralisÃ©
â”œâ”€ Indexer pour recherche rapide
â””â”€ Visualiser et analyser
```

### Architecture GÃ©nÃ©rique de Logging

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚â”€â”€â”
â”‚ (stdout)    â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”œâ”€â”€â”€â–¶â”‚ Collecte â”‚â”€â”€â”€â–¶â”‚ Stockageâ”‚â”€â”€â”€â–¶â”‚Visualisationâ”‚
â”‚ Application â”‚â”€â”€â”˜    â”‚ (Agent)  â”‚    â”‚ (Index) â”‚    â”‚    (UI)    â”‚
â”‚ (logs file) â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Transformationâ”‚
                    â”‚  (Parsing)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants :**
1. **Collecte** : RÃ©cupÃ¨re les logs (Filebeat, Fluentd, Promtail)
2. **Transformation** : Parse et enrichit (Logstash, Fluentd)
3. **Stockage** : Indexe et stocke (Elasticsearch, Loki)
4. **Visualisation** : Interface de recherche (Kibana, Grafana)


### Configuration Docker Logging Driver

#### Au Niveau du Daemon

**/etc/docker/daemon.json :**

```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3",
    "labels": "production_status",
    "env": "os,customer"
  }
}
```

---

#### Au Niveau du Conteneur

```yaml
services:
  myapp:
    image: myapp:latest
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"
        labels: "service,environment"
```

#### Drivers Disponibles

| Driver | Usage | Performance |
|--------|-------|-------------|
| `json-file` | Par dÃ©faut, fichiers JSON | Moyenne |
| `syslog` | Envoi vers syslog | Bonne |
| `journald` | Systemd journald | Bonne |
| `fluentd` | Envoi vers Fluentd | Moyenne |
| `gelf` | Graylog | Bonne |
| `local` | OptimisÃ© performances | Excellente |
| `none` | Pas de logs | N/A |



### Stack EFK (Elasticsearch + Fluentd + Kibana)

#### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conteneurs  â”‚
â”‚   (stdout)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Fluentd    â”‚â”€â”€â”€â–¶â”‚Elasticsearch â”‚â”€â”€â”€â–¶â”‚ Kibana  â”‚
â”‚ (Collecte +  â”‚    â”‚  (Stockage + â”‚    â”‚  (UI)   â”‚
â”‚  Transform)  â”‚    â”‚   Indexation)â”‚    â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques :**
- **Fluentd** : Collecteur lÃ©ger et flexible
- **Elasticsearch** : Moteur de recherche full-text distribuÃ©
- **Kibana** : Interface de visualisation puissante
- **Ressources** : 4-8GB RAM minimum


#### Configuration Fluentd

**fluentd.conf :**

```xml
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Parser les logs JSON
<filter docker.**>
  @type parser
  key_name log
  <parse>
    @type json
  </parse>
</filter>

# Enrichir avec des mÃ©tadonnÃ©es
<filter docker.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    tag ${tag}
  </record>
</filter>

# Envoyer vers Elasticsearch
<match docker.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix docker
  flush_interval 5s
</match>
```

---

#### Configurer les Conteneurs pour Fluentd

```yaml
services:
  myapp:
    image: myapp:latest
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: docker.myapp
        fluentd-async-connect: "true"
```


### Stack ELK avec Filebeat

#### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conteneurs  â”‚
â”‚  (log files) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Filebeat   â”‚â”€â”€â”€â–¶â”‚ Logstash â”‚â”€â”€â”€â–¶â”‚Elasticsearch â”‚â”€â”€â”€â–¶â”‚ Kibana â”‚
â”‚  (Collecte)  â”‚    â”‚(Transform)â”‚    â”‚  (Stockage)  â”‚    â”‚  (UI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DiffÃ©rence avec Fluentd :**
- **Filebeat** : Plus lÃ©ger, spÃ©cialisÃ© fichiers
- **Logstash** : Parsing trÃ¨s puissant mais gourmand
- **Ressources** : 6-12GB RAM minimum


#### Configuration Filebeat

**filebeat.yml :**

```yaml
filebeat.inputs:
  # Logs des conteneurs Docker
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

# Enrichissement
processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~

# Output vers Logstash
output.logstash:
  hosts: ["logstash:5044"]

# Ou directement vers Elasticsearch (plus simple)
# output.elasticsearch:
#   hosts: ["elasticsearch:9200"]

logging.level: info
```


#### Configuration Logstash

**logstash.conf :**

```ruby
input {
  beats {
    port => 5044
  }
}

filter {
  # Parser les logs JSON
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }

  # Parser les timestamps
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # Extraire des champs depuis les logs
  grok {
    match => { "message" => "%{COMBINEDAPACHELOG}" }
  }

  # Nettoyer les champs inutiles
  mutate {
    remove_field => ["agent", "ecs", "host"]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "docker-logs-%{+YYYY.MM.dd}"
  }
  
  # Debug (optionnel)
  stdout { codec => rubydebug }
}
```

---

### Stack PLG (Promtail + Loki + Grafana)

#### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conteneurs  â”‚
â”‚   (stdout)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Promtail   â”‚â”€â”€â”€â–¶â”‚   Loki   â”‚â”€â”€â”€â–¶â”‚ Grafana â”‚
â”‚  (Collecte)  â”‚    â”‚(Stockage)â”‚    â”‚  (UI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Philosophie Loki :**
- Ne parse PAS les logs (contrairement Ã  ELK)
- Indexe uniquement les labels (metadata)
- Recherche en texte brut trÃ¨s rapide
- Consomme 10Ã— moins de ressources qu'Elasticsearch
- **Ressources** : 1-2GB RAM seulement


#### Configuration Loki

**loki-config.yml :**

```yaml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 15m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /loki/index
    cache_location: /loki/cache
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks

limits_config:
  retention_period: 720h  # 30 jours
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 720h
```


#### Configuration Promtail

**promtail-config.yml :**

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Logs des conteneurs Docker
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      # Extraire le nom du conteneur
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      # Extraire l'image
      - source_labels: ['__meta_docker_container_image']
        target_label: 'image'
      # Extraire le service Swarm
      - source_labels: ['__meta_docker_container_label_com_docker_swarm_service_name']
        target_label: 'service'
      # Extraire le nÅ“ud
      - source_labels: ['__meta_docker_container_label_com_docker_swarm_node_id']
        target_label: 'node_id'
    pipeline_stages:
      # Parser les logs JSON
      - json:
          expressions:
            level: level
            timestamp: timestamp
            message: message
      # Extraire le timestamp
      - timestamp:
          source: timestamp
          format: RFC3339
      # Labelliser par niveau
      - labels:
          level:
```

#### Configuration Datasource Grafana

**grafana-datasources.yml :**

```yaml
apiVersion: 1

datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
    jsonData:
      maxLines: 1000
```


### Comparaison des Stacks de Logging

| CritÃ¨re | EFK (Fluentd) | ELK (Filebeat) | PLG (Loki) |
|---------|---------------|----------------|------------|
| **ComplexitÃ©** | â­â­â­ | â­â­â­â­ | â­â­ |
| **Ressources** | 4-8GB RAM | 6-12GB RAM | 1-2GB RAM |
| **Parsing** | âœ… Puissant | âœ… TrÃ¨s puissant | âŒ Basique |
| **Indexation** | âœ… Full-text | âœ… Full-text | ğŸ”¸ Labels uniquement |
| **Vitesse recherche** | Rapide | Rapide | TrÃ¨s rapide |
| **CoÃ»t stockage** | Ã‰levÃ© | Ã‰levÃ© | Faible |
| **ScalabilitÃ©** | âœ… Bonne | âœ… Excellente | âœ… Excellente |
| **Courbe apprentissage** | Moyenne | Difficile | Facile |
| **IntÃ©gration Grafana** | âš ï¸ Via plugin | âš ï¸ Via plugin | âœ… Native |


### RequÃªtes de Recherche

#### Kibana (ELK/EFK)

```
# Recherche simple
container.name: "webapp"

# Recherche avec wildcard
message: "error*"

# Combinaison AND/OR
container.name: "webapp" AND level: "error"

# Range temporel
@timestamp: [now-1h TO now]

# AggrÃ©gation
COUNT(container.name) GROUP BY container.name
```


#### Loki (LogQL)

```
# Tous les logs d'un service
{service="webapp"}

# Filtrage par niveau
{service="webapp"} |= "error"

# Recherche regex
{service="webapp"} |~ "error|warning"

# Exclusion
{service="webapp"} != "debug"

# Parsing JSON
{service="webapp"} | json | level="error"

# MÃ©triques (rate)
rate({service="webapp"}[5m])

# Count par container
sum(count_over_time({job="docker"}[5m])) by (container)
```
